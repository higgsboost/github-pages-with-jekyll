---
title: "machine learning"
date: 2022-07-05


# Graph neural networks

[slides](https://petar-v.com/talks/GNN-Wednesday.pdf)
[Petar Velickovic deepmind video](https://www.youtube.com/watch?v=uF53xsT7mjc)

Nodes in a graphs are not assumed to be in any order. 

**Permutation invariant** is that if we have a permutation matrix $P$, we say a function $f(X)$ is permutation invariant if 

$$
f(PX) = f(X)
$$

The *Deep Sets* model (Zheer et al , NeuraIPS 17) gives a function

$$
f(X) = \phi (\sum_i \psi (x_i))
$$
Where $\psi, \phi$ are learnable functions.

**Permutation equivariance** is defined as:

$$
f(PX) = Pf(X)
$$

### Learning on sets
If each node has input $x_i$, then let the latent vector be the output of some function $\psi$: $\bold{h}_i = \psi(\bold{x}_i)$.

Then we arrive at the equivariant function blueprint:

$$
f(\bold{X}) = \phi 
\left(
\bigoplus_{i\in\text{nodes}} \psi(\bold{x_i})
\right)
$$


$\bigoplus$ is any permutation-invariant aggregator, i.e. sum, average, or maximum.



### Graph with tensorflow
[Petar's tensorflow video](https://www.youtube.com/watch?v=8owQBFAHw7E)

We can do the following with GNN outputs:
* Node classification
* Graph classification
* Link classification

#### Node classification
Let graph $g$ be unweighted and undirected. If we have a node feature matrix $H$ and a learnable node-wise shared linear transformation $W$, then we have latent matrix

$$
H^{\prime} = \sigma(AHW)
$$

We need to include the central node, allowing node $i$ to connect to itself. $A^\prime = A + I$. 

#### Mean pooling
We need to scale the output features using the degree matrix. Or, we can simply use the neighbourhood $N$:

$$
\vec{h}^\prime_i = \sigma\left(\sum_{j\in N_i} \frac{1}{|N_i|} \bold W \vec{h}_j\right)
$$

**Graph convolution networks (GCN)** simply uses $\sqrt{|N_I||N_j|}$ 

### Message passing neural networks (MPNN)
Let a message $\vec{m}_{ij}$ be a message from node $i\rightarrow j$, the message function is defined as : 

*all letters are vectors from here unless specified*

$$
m_{ij} = f_e (h_i, h_j, e_{ij}) : 
$$

Then aggregate all messages entering a node:

$$
h_i = f_v \left(h_i, \sum_{j\in N_i} m_{ji}\right)
$$

---
